---
layout: post
title: LLM（大規模言語モデル）と電力消費量，ビジネスモデルの今後
excerpt: LLM の電力消費量と電気代を推測してみます．
tags: machine-learning LLM
category: machine-learning
author: sano
---

私は機械学習に関して全くの専門外なのですが，
ChatGPT などの LLM（大規模言語モデル）の驚くべき能力と急速な技術進化に感銘を受けています．
ただし，LLM にはいくつかの問題が指摘されています．
たとえば，Hallucination（学習データに存在しない情報を勝手に作成してしまうこと），データセットの偏り，そしてプライバシー侵害などがあります．
とは言え，これらの問題は主に運用に関連する側面が強いように感じます．
たとえば，Hallucination の発生が問題な場合は，既存の検索エンジンを使用することで解決できるかもしれません．
個人的に，もっと本質的な問題だと思うのは， LLM が膨大な計算資源を必要とすることです．

本稿では LLM が要求する電力を非常に大雑把に見積もってみることで，
この凄まじいチャットボットのビジネスモデルが今後どのようになっていくのかについて考察したいと思います．

再度断っておきたいのですが，
私は機械学習に関して全くの専門外で，特に LLM を運用した経験は全くありません．
間違ったことを言います（断言）．

また，多段に仮定や推測を重ねているため，
本稿内で述べている数値には全く信頼性がありません．
桁があっていることは願っていますが，それも自信がありません．
より正確な数値をご存知の方は是非教えてください．

# LLM が要求する電力

LLM に限らず多くの機械学習では学習と推論のフェーズに分かれています．
学習時には膨大な数のデータを用いてパラメータの更新を何度も行うために，
一度だけ推論するのと比較すると学習のコストの方が遥かに大きいです．
とは言え，推論を何度も行えば推論コストの合計は大きくなっていきます．

Business Insider のブログでは，
OpenAI 社が「ChatGPT の推論コストは週単位では学習コストを上回る」と回答したとしています． [^1]
またこのブログ [^2] では
「NVIDEA と Amazon AWS は機械学習関連の計算のうち最大 90% 以上が推論に用いられていると推測している」
としています（ただし，私はこのブログ内でこの発言の根拠として挙げている文献 10 [^10] 内にこの発言を見つけることができませんでした）．

この先， LLM はより多く活用されることになり，
推論の回数は更に劇的に増加し，
推論コストが LLM にかかるコストの大部分を占めると考えられるのではないかと思います．
従って，ひとまず推論コストについてのみ考えることにしたいと思います
（学習時のコストについても，時間を作ってもう少し調べてみます）．

推論にはハードウェア（GPU マシン）と膨大な電力が必要です．
ハードウェア調達のコストは推論を何度も行えば按分され小さくなると仮定し，無視します．
LLM の推論時の電力消費量について調査しました．

GPT3, 3.5, 4 の推論時の電力消費量は恐らく公開されていないと思う（どなたか見つけたら教えてください）のですが，
BLOOM と言う 176B（1760 億）パラメータの LLM の運用時の電力消費量に言及している文献 [^4] を見つけました．
パラメータというのは LLM の指標で，これが大きいほど性能がよく，また大きな電力を消費します．
GPT3 は 175B パラメータのモデルであるので，BLOOM (176B) と恐らくは同じくらいの電力を消費すると仮定できると思います．

この文献によると，BLOOM の運用には合計 914 kWh のエネルギーを消費しています．
クエリの回数の合計は 230,768 なので，
**1 クエリあたり平均 3.96 Wh の電力を消費しています．**

BLOOM の運用に関する文献から，
GPT3 の推論コストも 1 クエリあたり約 4 Wh と推測したわけですが，もう少し別の角度からも推測してみます．
このブログ [^5] によると，2022 年初頭時点で世界最高性能の NVIDEA 社の GPU，
A100 をフルパワーで動かすと 2,400W ほどの電力を消費するようです．
つまり，A100 を 6 秒動かすと 4Wh の電力を消費することになります．
6 秒というのは，GPT3 が解答を返し終わるまでにかかる時間としてはそれなりに妥当
（桁はあっていそう）なのではと思います．
従って 1 クエリあたり約 4 Wh というのはある程度妥当な値なのではと思います
（これはかなり雑な議論だと思います．実際の運用は遥かに複雑なのだろうと思います）．

# LLM の電気代

GPT3 の推論コストは約 4 Wh と見積もりました．
その電気代も見積もりたいと思います．
電気代は場所によって大きく違いますが，今回は推論が東京で行われていると仮定してみます
（今までもこれからもそのようなことはないと思いますが）．

東京での電気料金 1kWh あたりの目安単価（2023 年 6 月以降）は，約 39 円なようです．[^6]
従って BLOOM 1 クエリあたり約 0.16 円かかるという計算になります．

ここで OpenAI の価格表 [^7] を見ると，
GPT-3.5 Turbo は 1K トークンあたり約 0.5 円かかります
（8K context，1$=146 円で計算）．
1 クエリ 1K トークンで，
BLOOM と推論時の電力が同じで，東京で推論していると仮定すると，約 32% が電気代というわけです．

GPT4 は 1K トークンあたり約 13 円かかります．
価格が計算量に比例していると仮定すると，GPT4 の計算量は GPT-3.5 Turbo の 26 倍となり，
一度の推論に 104 Wh かかる計算になります．
この場合の電気代は約 4.2 円です．

日本での一人暮らしの電力消費量は一日あたり約 6 kWh らしいです．[^8]
つまり GPT4 に 60 回以上クエリを投げると一日あたりの電力消費量を上回ります．
「LLM で暮らしを全部サポート，全ての家電に LLM が組み込まれて毎分毎秒やり取りします」
とかしようとすると電力消費量がすごいことになることが想像できます．

# GPT5 について

個人的な意見ですが，
多くの人は 1 クエリに 100 円以上かかるのであれば，
ChatGPT に聞かずにググって自分で考えると思います．
GPT4 が GPT 3.5 Turbo の 26 倍の値段がするように，
GPT5 が GPT4 の 26 倍の値段（338 円）かかるのであれば普通の人は使わないと思います．
GPT5 の電気代も GPT4 の 26 倍だすると 109 円となり，
赤字を覚悟してこの電気代の分だけをユーザに要求したとしても，
使う人は少ないのではないかと予想します．

従って，OpenAI にとってもこれ以上このままスケールさせるモチベーションは大きくないのではないか？
というのがひとまずの個人的な素朴な感想です．
ただし技術革新により劇的にコストが下がる可能性は大きいと思っており，
今後の動向に注意したいと思います．

# LLM ビジネスモデルの未来

先述の通り，
LLM を素朴にスケールさせる競争はひとまず臨界点に達しつつあるのではという感想を抱いています．
汎用性の高いチャットボットとしての LLM は，
ビジネスモデルとしてはもうすでに完成形に到達しつつあるのではないでしょうか．
日本企業はまだそこまで到達できていませんし，
この先到達できるのかも分かりませんが．

個人的には，
多くの企業は LLM をより大規模にしていく競争から，
活用シーンを見極めた上で軽量化する研究へより投資してゆくのではないかと思います．

とは言え，これは想像力に欠けた感想かも知れません．
ChatGPT とやりとりをしていると毎回驚かされます．
2 年前には想像もしていなかった体験をしています．

[^1]:
    ChatGPT could cost over $700,000 per day to operate. Microsoft is reportedly trying to make it cheaper.
    <https://www.businessinsider.com/how-much-chatgpt-costs-openai-to-run-estimate-report-2023-4>
    OpenAI は一日あたり 1 億 234 万 2800 円かかっているらしいです．

[^2]:
    Here Comes the Sun! Why Large Language Models Don’t have to Cost the Earth
    <https://www.linkedin.com/pulse/here-comes-sun-why-large-language-models-dont-have-cost-paul-walsh/>

[^10]:
    A. TALWALKAR, "AI in the 2020s Must Get Greener—and Here’s How," 14 February 2020. [Online].
    <https://spectrum.ieee.org/energy-efficient-green-ai-strategies>

[^4]:
    Estimating the Carbon Footprint of BLOOM, a 176B Parameter Language Model
    <https://www.jmlr.org/papers/volume24/23-0069/23-0069.pdf>

[^5]:
    blog: NVIDIA DGX™ A100 徹底検証！Vol.1
    <https://www.nttpc.co.jp/gpu/article/benchmark10.html>

[^6]:
    一般家庭の電気使用量は平均いくら？意外と知らない 1kwh あたりの電気代
    <https://htb-energy.com/article/price/a36>

[^7]:
    OpenAI, Pricing
    <https://openai.com/pricing>

[^8]:
    自宅の電気料金の使用量を知るには？使用量を減らして節電するポイントも解説！
    <https://ecodenchi.com/electricitypost-cut/>

---

[blog: Predicting and Reducing Energy Consumption of Machine Learning Models
](https://datatonic.com/insights/predicting-reducing-energy-consumption-machine-learning-models/)

- Figure 7: Regression line on inference energy consumption per request から，
  BERT base (110M parameters) の 1 query の電力消費量は約 40 J と読み取れる．
- $40 / 3,600 * (176 * 1,000) / 110 = 17.8$ であるので，
  電力消費量がパラメータ数に比例するとすれば GPT3 の電力消費量は 17.8 Wh となる．
